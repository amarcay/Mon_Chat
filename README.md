# MonChat - Application de Chat IA Multimodale

MonChat est une application web interactive que jâ€™ai mise en place en tant quâ€™Ã©tudiant pour explorer le fonctionnement des RAG, des agents IA et de Docker. Elle permet dâ€™interagir avec diffÃ©rents types de contenu (PDF, CSV) via une interface de chat exploitant lâ€™Intelligence Artificielle.

## ğŸ¯ Objectif

Cette application vise Ã  fournir une interface unifiÃ©e pour interagir avec diffÃ©rents types de contenu en utilisant l'Intelligence Artificielle. Elle permet aux utilisateurs de :
- Analyser et interroger des documents PDF
- Explorer et analyser des donnÃ©es CSV
- GÃ©nÃ©rer du contenu pour des articles de blog
- Extraire et analyser du contenu web
- Interagir directement avec un modÃ¨le de langage

## ğŸš€ FonctionnalitÃ©s

- **Chat Classique** : Interaction directe avec le modÃ¨le Llama3.2
- **Chat PDF** : Analyse et interrogation de documents PDF
- **Chat CSV** : Analyse et interrogation de fichiers CSV
- **Chat Blog** : GÃ©nÃ©ration d'articles de blog
- **Scrapper Web** : Extraction et analyse de contenu web
- **Chat CSV & Agent SQL** : Analyse et interrogation de fichiers CSV Ã  l'aide de d'agent SQL

## ğŸ—ï¸ Architecture

L'application est construite avec :
- **Frontend** : Streamlit pour l'interface utilisateur
- **Backend** : 
  - Ollama pour les modÃ¨les de langage
  - LangChain pour l'intÃ©gration IA
  - ChromaDB pour le stockage vectoriel
  - SQLAlchemy pour la gestion des donnÃ©es CSV

## ğŸ“‹ PrÃ©requis

- Docker (version 20.10 ou supÃ©rieure)
- Docker Compose (version 2.0 ou supÃ©rieure)
- Git
- Au moins 8GB de RAM recommandÃ©s
- 20GB d'espace disque libre recommandÃ©

## ğŸ› ï¸ Installation

1. Cloner le repository :
```bash
git clone https://github.com/amarcay/MonChat.git
cd MonChat
```

2. CrÃ©er les dossiers nÃ©cessaires :
```bash
mkdir -p data/CSV data/PDF chroma_db
```

3. DÃ©marrer l'application avec Docker Compose :
```bash
docker-compose up --build
```

4. TÃ©lÃ©charger le modÃ¨le Llama3.2 :
```bash
docker-compose exec ollama ollama pull llama3.2
```

## ğŸŒ AccÃ¨s Ã  l'Application

Une fois l'application dÃ©marrÃ©e, vous pouvez y accÃ©der via votre navigateur :
- Interface principale : http://localhost:8501

## ğŸ“ Structure du Projet

```
MonChat/
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ 1_Le_Chat_du_PDF.py
â”‚   â”œâ”€â”€ 2_Le_Chat_du_CSV.py
â”‚   â”œâ”€â”€ 3_Le_Chat_du_BLOG.py
â”‚   â”œâ”€â”€ 4_Le_Scrapper_Fou.py
â”‚   â””â”€â”€ 5_Le_Chat_du_CSV_et_L_Agent_SQL.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ CSV/
â”‚   â””â”€â”€ PDF/
â”œâ”€â”€ chroma_db/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ Le_Classique_Chat.py
```

## ğŸ”§ Configuration

### Variables d'Environnement

L'application utilise les variables d'environnement suivantes :
- `OLLAMA_HOST` : URL du service Ollama (configurÃ© automatiquement dans docker-compose)
- `LANGSMITH_TRACING` : Activation du traÃ§age LangSmith
- `LANGSMITH_API_KEY` : ClÃ© API pour LangSmith
- `LANGSMITH_ENDPOINT` : Point d'accÃ¨s LangSmith
- `LANGSMITH_PROJECT` : Nom du projet LangSmith

### Volumes Docker

- `data/` : Stockage des fichiers CSV et PDF
- `chroma_db/` : Base de donnÃ©es vectorielle
- `ollama_data` : ModÃ¨les Ollama

## ğŸ“¦ DÃ©pendances Principales

- **streamlit==1.32.0** : Interface utilisateur
- **langchain==0.1.12** : Framework d'intÃ©gration IA
- **ollama==0.1.6** : Client Ollama
- **pandas==2.2.1** : Manipulation des donnÃ©es
- **chromadb==0.4.24** : Base de donnÃ©es vectorielle
- **sentence-transformers==2.5.1** : ModÃ¨les d'embeddings
- **crewai==0.16.0** : Orchestration des agents IA

## ğŸš€ Utilisation

### Chat Classique
1. AccÃ©dez Ã  l'interface principale
2. Posez vos questions directement dans le chat

### Chat PDF
1. TÃ©lÃ©chargez un fichier PDF
2. Posez des questions sur son contenu
3. Le systÃ¨me analysera automatiquement le contenu et rÃ©pondra Ã  vos questions

### Chat CSV
1. TÃ©lÃ©chargez un fichier CSV
2. Interrogez vos donnÃ©es
3. Le systÃ¨me analysera automatiquement le contenu et rÃ©pondra Ã  vos questions

### Chat Blog
1. Entrez un sujet
2. L'application gÃ©nÃ©rera un article complet
3. Le contenu sera structurÃ© avec introduction, dÃ©veloppement et conclusion

### Scrapper Web
1. Entrez une URL
2. L'application analysera le contenu du site
3. Obtenez un rÃ©sumÃ© et des insights sur le contenu

### Chat CSV & L'Agent SQL
1. TÃ©lÃ©chargez un fichier CSV
2. SpÃ©cifiez le nom de la table
3. Interrogez vos donnÃ©es
4. Utilisez des requÃªtes naturelles pour analyser vos donnÃ©es

## ğŸ› ï¸ Maintenance

### RedÃ©marrage des Services
```bash
docker-compose restart
```

### ArrÃªt de l'Application
```bash
docker-compose down
```

### Voir les Logs
```bash
docker-compose logs -f
```

### Nettoyage des DonnÃ©es
```bash
# Supprimer les volumes Docker
docker-compose down -v

# Nettoyer les dossiers de donnÃ©es
rm -rf data/* chroma_db/*
```

## ğŸ” DÃ©pannage

### ProblÃ¨mes Courants

1. **Erreur de connexion Ã  Ollama**
   - VÃ©rifiez que le service Ollama est en cours d'exÃ©cution
   - Assurez-vous que le modÃ¨le llama3.2 est tÃ©lÃ©chargÃ©

2. **ProblÃ¨mes de mÃ©moire**
   - Augmentez la mÃ©moire allouÃ©e Ã  Docker
   - Fermez les applications non essentielles

3. **Erreurs de chargement de fichiers**
   - VÃ©rifiez les permissions des dossiers data/
   - Assurez-vous que les fichiers ne sont pas corrompus

## ğŸ“ Notes

- Les modÃ¨les Ollama sont stockÃ©s dans un volume Docker persistant
- Les fichiers CSV et PDF sont stockÃ©s localement dans le dossier `data/`
- La base de donnÃ©es vectorielle est stockÃ©e dans `chroma_db/`
- Le systÃ¨me utilise des embeddings pour une recherche sÃ©mantique efficace
- Les rÃ©ponses sont gÃ©nÃ©rÃ©es en temps rÃ©el avec streaming

## ğŸ”’ SÃ©curitÃ©

- Les fichiers sont traitÃ©s localement
- Aucune donnÃ©e n'est envoyÃ©e Ã  des services externes (sauf LangSmith si activÃ©)
- Les fichiers temporaires sont nettoyÃ©s automatiquement

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :
1. Fork le projet
2. CrÃ©er une branche pour votre fonctionnalitÃ©
3. Commiter vos changements
4. Pousser vers la branche
5. Ouvrir une Pull Request

### Guidelines de Contribution

- Suivez les conventions de code Python (PEP 8)
- Ajoutez des tests pour les nouvelles fonctionnalitÃ©s
- Mettez Ã  jour la documentation si nÃ©cessaire
- Assurez-vous que tous les tests passent avant de soumettre une PR

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

## ğŸ‘¥ Auteurs

- Alphonse MarÃ§ay - [@amarcay](https://github.com/amarcay)
